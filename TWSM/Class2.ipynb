{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markusloecher/DataScience2021/blob/main/TWSM/Class2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "-B3RMcw6CeZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# function for transformation\n",
        "def transform_df(text):\n",
        "    \n",
        "    (unique, counts) = np.unique(text.split(), return_counts=True)\n",
        "    df_words = pd.DataFrame(unique, counts).reset_index().rename(columns = {\"index\":\"counts\", 0:\"word\"}).sort_values(by = \"counts\", ascending = False)\n",
        "    df_words[\"rank\"] =  df_words[\"counts\"].rank(ascending=False)\n",
        "    \n",
        "    return df_words\n",
        "\n",
        "\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "def tf_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] += 1.\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "cVATPaIWf6cG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Sets"
      ],
      "metadata": {
        "id": "eH2B6Yzmf4_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AczlUWfwpd6",
        "outputId": "400ed01b-aacb-41df-ca7d-b83e3deb140a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TWSM_path = \"/content/drive/MyDrive/teaching/TWSM/WorkInClass/\"\n",
        "bing = pd.read_csv(TWSM_path+\"bing.csv\")\n",
        "\n",
        "bing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4qfh7ik6Pii9",
        "outputId": "144a6f6d-0477-4809-c1b1-5cf0292a7e09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0        word sentiment\n",
              "0              1     2-faces  negative\n",
              "1              2    abnormal  negative\n",
              "2              3     abolish  negative\n",
              "3              4  abominable  negative\n",
              "4              5  abominably  negative\n",
              "...          ...         ...       ...\n",
              "6781        6782   zealously  negative\n",
              "6782        6783      zenith  positive\n",
              "6783        6784        zest  positive\n",
              "6784        6785       zippy  positive\n",
              "6785        6786      zombie  negative\n",
              "\n",
              "[6786 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d2bbf7b-4f5d-4324-9608-733773b04812\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>word</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2-faces</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>abolish</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>abominable</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>abominably</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6781</th>\n",
              "      <td>6782</td>\n",
              "      <td>zealously</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6782</th>\n",
              "      <td>6783</td>\n",
              "      <td>zenith</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6783</th>\n",
              "      <td>6784</td>\n",
              "      <td>zest</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6784</th>\n",
              "      <td>6785</td>\n",
              "      <td>zippy</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6785</th>\n",
              "      <td>6786</td>\n",
              "      <td>zombie</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6786 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d2bbf7b-4f5d-4324-9608-733773b04812')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d2bbf7b-4f5d-4324-9608-733773b04812 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d2bbf7b-4f5d-4324-9608-733773b04812');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2qNHjmb0Pyhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wqKAMATyPyPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gutenberg"
      ],
      "metadata": {
        "id": "a1yymRS8ta7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gutenberg\n",
        "\n",
        "from gutenberg.acquire import load_etext\n",
        "from gutenberg.cleanup import strip_headers"
      ],
      "metadata": {
        "id": "_z87j_urtv6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = strip_headers(load_etext(42671)).strip()\n",
        "#text = load_etext(42671)\n",
        "#print(text)"
      ],
      "metadata": {
        "id": "vKy-W6a-twxh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TWSM_path = \"/content/drive/MyDrive/teaching/TWSM/WorkInClass/\"\n",
        "afinn = pd.read_csv(TWSM_path+\"afinn.csv\")\n",
        "\n",
        "afinn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rPYoge-eiNcc",
        "outputId": "63ed03a8-78ce-40d8-874f-32aed9990c31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0       word  value\n",
              "0              1    abandon     -2\n",
              "1              2  abandoned     -2\n",
              "2              3   abandons     -2\n",
              "3              4   abducted     -2\n",
              "4              5  abduction     -2\n",
              "...          ...        ...    ...\n",
              "2472        2473      yucky     -2\n",
              "2473        2474      yummy      3\n",
              "2474        2475     zealot     -2\n",
              "2475        2476    zealots     -2\n",
              "2476        2477    zealous      2\n",
              "\n",
              "[2477 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c740f181-09b4-48e4-a226-d85dc5a3bb33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>word</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>abandon</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>abandoned</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>abandons</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>abducted</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>abduction</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2472</th>\n",
              "      <td>2473</td>\n",
              "      <td>yucky</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>2474</td>\n",
              "      <td>yummy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>2475</td>\n",
              "      <td>zealot</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>2476</td>\n",
              "      <td>zealots</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>2477</td>\n",
              "      <td>zealous</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2477 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c740f181-09b4-48e4-a226-d85dc5a3bb33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c740f181-09b4-48e4-a226-d85dc5a3bb33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c740f181-09b4-48e4-a226-d85dc5a3bb33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic = afinn\n",
        "dic\n",
        "#sentiment_merge = pd.merge(dic, df_words, how=\"inner\", on=\"word\")\n",
        "#sentiment_merge = pd.merge(dic, df_words, left_on=\"word\", right_on=\"words\")\n",
        "#sentiment_merge[\"total_value\"] = sentiment_merge[\"value\"] * sentiment_merge[\"counts\"]\n",
        "#ovr_score = np.mean(sentiment_merge[\"total_value\"])\n",
        "\n",
        "#print(ovr_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "bIH6ufMKhzqM",
        "outputId": "3c568b98-b0b0-4fde-fa2b-3040e48849a6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0       word  value\n",
              "0              1    abandon     -2\n",
              "1              2  abandoned     -2\n",
              "2              3   abandons     -2\n",
              "3              4   abducted     -2\n",
              "4              5  abduction     -2\n",
              "...          ...        ...    ...\n",
              "2472        2473      yucky     -2\n",
              "2473        2474      yummy      3\n",
              "2474        2475     zealot     -2\n",
              "2475        2476    zealots     -2\n",
              "2476        2477    zealous      2\n",
              "\n",
              "[2477 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c85b559c-921d-4d58-923d-b70b36a8f1f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>word</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>abandon</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>abandoned</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>abandons</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>abducted</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>abduction</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2472</th>\n",
              "      <td>2473</td>\n",
              "      <td>yucky</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>2474</td>\n",
              "      <td>yummy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>2475</td>\n",
              "      <td>zealot</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>2476</td>\n",
              "      <td>zealots</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>2477</td>\n",
              "      <td>zealous</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2477 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c85b559c-921d-4d58-923d-b70b36a8f1f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c85b559c-921d-4d58-923d-b70b36a8f1f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c85b559c-921d-4d58-923d-b70b36a8f1f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e3ofzmU3fbUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMD Movie Reviews\n"
      ],
      "metadata": {
        "id": "QG0vmczitVQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Loading the IMDB dataset***"
      ],
      "metadata": {
        "id": "ljUFLmLJtlnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMLV2uy1tmpe",
        "outputId": "cc525844-8bd9-40b3-f9cb-1aa397ab26b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaZfgKVdy0hR",
        "outputId": "853bef23-c0ee-4118-ea4f-eb1e2fb8589a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_labels, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWWjvxT_xm9G",
        "outputId": "2813218e-03e2-4224-acaf-d2ee9a779781"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([12500, 12500]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoding reviews back to text**"
      ],
      "metadata": {
        "id": "6xrmGZDsPfUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])\n",
        "\n",
        "decoded_review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "muyre50UtroS",
        "outputId": "170852e9-9d9f-4419-b8df-54923e527602"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=len(train_data)\n",
        "decoded_reviews = [\"\" for x in range(N)]\n",
        "\n",
        "for j in range(N):\n",
        "  decoded_reviews[j] = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[j]])"
      ],
      "metadata": {
        "id": "1Mo-oPtJPj6r"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_reviews[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "yoFU1QWw0nQq",
        "outputId": "1b42801d-f20f-4c48-bbd4-9b1b99fd4678"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.ma.core import zeros\n",
        "#dic=afinn\n",
        "def SentByReview(decoded_review, dic):\n",
        "  df_words= transform_df(decoded_review)\n",
        "  #df_words.head()\n",
        "  #sentiment_merge = pd.merge(dic, df_words, how=\"inner\", on=\"words\")\n",
        "  sentiment_merge = pd.merge(dic, df_words, left_on=\"word\", right_on=\"word\")\n",
        "  sentiment_merge[\"total_value\"] = sentiment_merge[\"value\"] * sentiment_merge[\"counts\"]\n",
        "  ovr_score = np.mean(sentiment_merge[\"total_value\"])\n",
        "  return ovr_score\n",
        "\n",
        "N = len(decoded_reviews)\n",
        "SentScore = np.zeros(N)\n",
        "\n",
        "for i in range(N):\n",
        "  SentScore[i] = SentByReview(decoded_reviews[i], afinn)"
      ],
      "metadata": {
        "id": "IQtwPGba09cG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "SentimentByLabel = pd.DataFrame(y_train, SentScore).reset_index().rename(columns = {\"index\":\"sentiment\", 0:\"label\"})\n",
        "\n",
        "SentimentByLabel.boxplot(by=\"label\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "kxu7me9v5jvh",
        "outputId": "7a305875-ab34-46ad-855e-9f94650db6c4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(SentScore>0, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "BWBiQ3n6AGAA",
        "outputId": "0209dade-09a5-4c8b-a7f4-9e0579800143"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0   0.0    1.0\n",
              "row_0             \n",
              "False  6827   1905\n",
              "True   5673  10595"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b033bed-3bbd-4cb8-a3ed-eb3fd4907f5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>6827</td>\n",
              "      <td>1905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>5673</td>\n",
              "      <td>10595</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b033bed-3bbd-4cb8-a3ed-eb3fd4907f5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b033bed-3bbd-4cb8-a3ed-eb3fd4907f5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b033bed-3bbd-4cb8-a3ed-eb3fd4907f5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #!pip install copy\n",
        "  from copy import deepcopy\n",
        "  \n",
        "  np.sum(np.isnan(SentScore))\n",
        "  SentScore2 = deepcopy(SentScore)\n",
        "  SentScore[np.isnan(SentScore)]=0"
      ],
      "metadata": {
        "id": "6k1zIVwp4TBr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")\n",
        "\n",
        "model = sm.OLS(y_train, SentScore).fit()\n",
        "#predictions = model.predict(X) \n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "SVQ33mJR3GwU",
        "outputId": "5b33ddd7-db07-4605-cbf8-b378571a4066"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.362\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.362\n",
              "Method:                 Least Squares   F-statistic:                          1.416e+04\n",
              "Date:                Tue, 12 Apr 2022   Prob (F-statistic):                        0.00\n",
              "Time:                        13:26:26   Log-Likelihood:                         -21198.\n",
              "No. Observations:               25000   AIC:                                  4.240e+04\n",
              "Df Residuals:                   24999   BIC:                                  4.241e+04\n",
              "Df Model:                           1                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1             0.3088      0.003    119.005      0.000       0.304       0.314\n",
              "==============================================================================\n",
              "Omnibus:                     1278.159   Durbin-Watson:                   1.322\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4388.675\n",
              "Skew:                           0.157   Prob(JB):                         0.00\n",
              "Kurtosis:                       5.028   Cond. No.                         1.00\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.362</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.362</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>1.416e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 12 Apr 2022</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>13:26:26</td>     <th>  Log-Likelihood:    </th>          <td> -21198.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 25000</td>      <th>  AIC:               </th>          <td>4.240e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 24999</td>      <th>  BIC:               </th>          <td>4.241e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>    0.3088</td> <td>    0.003</td> <td>  119.005</td> <td> 0.000</td> <td>    0.304</td> <td>    0.314</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>1278.159</td> <th>  Durbin-Watson:     </th> <td>   1.322</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4388.675</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 0.157</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td> 5.028</td>  <th>  Cond. No.          </th> <td>    1.00</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Matrix"
      ],
      "metadata": {
        "id": "SvnR5jxE20xU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n"
      ],
      "metadata": {
        "id": "sZE5PiNa2sJI"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
        "clf.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvJcbQOH7ku4",
        "outputId": "6c2213bb-a2c2-4e8f-c322-3dcce75379b1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 10000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=20, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yHat_train =clf.predict(x_train)\n",
        "yHat_test =clf.predict(x_test)"
      ],
      "metadata": {
        "id": "WG2FrFUg8kV9"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "pd.crosstab(yHat_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "8iunPiKp8raL",
        "outputId": "019d5a8e-d308-4502-d788-19563bad2798"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0    0.0    1.0\n",
              "row_0              \n",
              "0.0    11233    364\n",
              "1.0     1267  12136"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2aee444-2e94-45bd-9064-5c7c0c79a992\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>11233</td>\n",
              "      <td>364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1267</td>\n",
              "      <td>12136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2aee444-2e94-45bd-9064-5c7c0c79a992')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2aee444-2e94-45bd-9064-5c7c0c79a992 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2aee444-2e94-45bd-9064-5c7c0c79a992');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "pd.crosstab(yHat_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "jIsTRxSO8-XK",
        "outputId": "0fdb3932-44e0-462d-ae1f-f3fbdc1e0163"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0    0.0    1.0\n",
              "row_0              \n",
              "0.0    10108   1699\n",
              "1.0     2392  10801"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e493f014-898f-4553-850e-27880b0ba086\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>10108</td>\n",
              "      <td>1699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>2392</td>\n",
              "      <td>10801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e493f014-898f-4553-850e-27880b0ba086')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e493f014-898f-4553-850e-27880b0ba086 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e493f014-898f-4553-850e-27880b0ba086');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge"
      ],
      "metadata": {
        "id": "cj2CkT1i8jUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(\"robert\", decoded_review)"
      ],
      "metadata": {
        "id": "DAp3KFrlPt-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tasks\n",
        "\n",
        "Build a classifier on the train data in at least five different ways:\n",
        "\n",
        "1. using sentiment analysis\n",
        "2. using term frequencies in at least **4** different flavors.\n",
        "\n",
        "The data set in 2. is VERY high-dimensional so please choose a classifier that can deal with feature selection."
      ],
      "metadata": {
        "id": "aahZJsZnisW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "vec_abs= CountVectorizer(max_df=0.95, min_df=0.05) #Absolute frequency\n",
        "vec_rel = TfidfVectorizer(max_df=0.95, min_df=0.05, use_idf=False, norm='l1') # Relative frequency\n",
        "vec_tf=TfidfVectorizer(max_df=0.95, min_df=0.05, smooth_idf=False) #Tf-IDF frequency\n",
        "\n",
        "# Tranform stemmed data\n",
        "corpus_sk_abs=vec_abs.fit_transform(decoded_reviews)\n",
        "#corpus_sk_bin=vec_bin.fit_transform(corpus_sk_abs)\n",
        "#corpus_sk_rel=vec_rel.fit_transform(data_stem)\n",
        "#corpus_sk_tf=vec_tf.fit_transform(data_stem)"
      ],
      "metadata": {
        "id": "Kv7IhR_yCaFd"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_sk_abs[0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VM0nWchDXpO",
        "outputId": "27187184-8c66-4a12-8e7a-0327f99a5523"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "For each movie review\n",
        "1. Get all bigrams\n",
        "2. Filter the ones with \"not\" in first position\n",
        "3. Reverse the sentiment analysis\n"
      ],
      "metadata": {
        "id": "Ac3hLN48UyAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two-gram absolute transformer (min=max=2 words)\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2), max_df=1, min_df=0)\n",
        "\n",
        "corpus_sk_bi=bigram_vectorizer.fit_transform(decoded_reviews)\n",
        "bigrams = bigram_vectorizer.get_feature_names()\n",
        "print(bigrams)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP8SbGqlD9I2",
        "outputId": "d6ef35dc-e2ed-47e5-d469-7ddb491c058c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(bigrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLcPdCXlYCNX",
        "outputId": "9f29bae5-0925-4a70-8dd5-d6fd5f8da388"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "678566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for f in bigrams:\n",
        "  if (re.findall(\"^not \",f)): print(f)\n",
        "  #if (f.count(\"not\")>0): print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-w5IL9bXVS2",
        "outputId": "45f46baf-96aa-4b89-d912-7ad58e3d3feb"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not 12\n",
            "not 14\n",
            "not 15\n",
            "not 1944\n",
            "not 1963\n",
            "not 1965\n",
            "not 1971\n",
            "not 1985\n",
            "not 1986\n",
            "not 1992\n",
            "not 2007\n",
            "not 24\n",
            "not 2nd\n",
            "not 30\n",
            "not 3rd\n",
            "not 40\n",
            "not 50\n",
            "not ability\n",
            "not abraham\n",
            "not abrupt\n",
            "not absolute\n",
            "not absurd\n",
            "not abuse\n",
            "not abysmal\n",
            "not academy\n",
            "not accidental\n",
            "not accomplish\n",
            "not accurately\n",
            "not achieve\n",
            "not acknowledge\n",
            "not active\n",
            "not acts\n",
            "not adam\n",
            "not adaptation\n",
            "not addressed\n",
            "not adds\n",
            "not admiration\n",
            "not adolescent\n",
            "not adore\n",
            "not adults\n",
            "not advance\n",
            "not advanced\n",
            "not advertising\n",
            "not affecting\n",
            "not agreed\n",
            "not aid\n",
            "not aimed\n",
            "not akin\n",
            "not akshay\n",
            "not alas\n",
            "not alcohol\n",
            "not alert\n",
            "not alike\n",
            "not alive\n",
            "not almost\n",
            "not alot\n",
            "not ambitious\n",
            "not america\n",
            "not americans\n",
            "not andy\n",
            "not anger\n",
            "not angie\n",
            "not annoyance\n",
            "not annoyingly\n",
            "not answered\n",
            "not ants\n",
            "not apocalypse\n",
            "not apocalyptic\n",
            "not apologize\n",
            "not apparent\n",
            "not appealing\n",
            "not applied\n",
            "not approach\n",
            "not arguing\n",
            "not ariel\n",
            "not arnie\n",
            "not arnold\n",
            "not arrogant\n",
            "not artsy\n",
            "not asian\n",
            "not asked\n",
            "not assume\n",
            "not astonishingly\n",
            "not attempted\n",
            "not attend\n",
            "not attended\n",
            "not attracted\n",
            "not audiences\n",
            "not automatic\n",
            "not average\n",
            "not avid\n",
            "not avoided\n",
            "not awfully\n",
            "not baby\n",
            "not baker\n",
            "not balanced\n",
            "not balls\n",
            "not bare\n",
            "not baseball\n",
            "not bash\n",
            "not bashing\n",
            "not basic\n",
            "not basically\n",
            "not basket\n",
            "not bass\n",
            "not batman\n",
            "not bearing\n",
            "not beaten\n",
            "not beatles\n",
            "not beautifully\n",
            "not became\n",
            "not beer\n",
            "not beforehand\n",
            "not beings\n",
            "not bela\n",
            "not belief\n",
            "not believed\n",
            "not belly\n",
            "not bend\n",
            "not benefit\n",
            "not beowulf\n",
            "not besides\n",
            "not betrayed\n",
            "not bigger\n",
            "not bill\n",
            "not bitch\n",
            "not bitchy\n",
            "not bizarre\n",
            "not blair\n",
            "not bland\n",
            "not bleed\n",
            "not blind\n",
            "not blink\n",
            "not block\n",
            "not blow\n",
            "not blunt\n",
            "not bob\n",
            "not bold\n",
            "not bomb\n",
            "not books\n",
            "not boss\n",
            "not bothered\n",
            "not bound\n",
            "not boy\n",
            "not brad\n",
            "not brainless\n",
            "not braveheart\n",
            "not breath\n",
            "not breathing\n",
            "not brett\n",
            "not brian\n",
            "not brief\n",
            "not bright\n",
            "not brilliantly\n",
            "not bringing\n",
            "not british\n",
            "not brits\n",
            "not bryan\n",
            "not buddy\n",
            "not bug\n",
            "not built\n",
            "not bulk\n",
            "not bullet\n",
            "not buried\n",
            "not burn\n",
            "not burning\n",
            "not business\n",
            "not cable\n",
            "not cage\n",
            "not cannot\n",
            "not captain\n",
            "not captivated\n",
            "not car\n",
            "not carefully\n",
            "not caricatures\n",
            "not carmen\n",
            "not carrey\n",
            "not cartoons\n",
            "not cary\n",
            "not cash\n",
            "not cassidy\n",
            "not casual\n",
            "not cat\n",
            "not catching\n",
            "not catchy\n",
            "not causing\n",
            "not celebrating\n",
            "not celebration\n",
            "not center\n",
            "not centuries\n",
            "not century\n",
            "not cerebral\n",
            "not certainly\n",
            "not chances\n",
            "not characteristic\n",
            "not charged\n",
            "not charlie\n",
            "not chase\n",
            "not cheating\n",
            "not checking\n",
            "not chick\n",
            "not childish\n",
            "not chinese\n",
            "not choose\n",
            "not choosing\n",
            "not chore\n",
            "not chris\n",
            "not christianity\n",
            "not christmas\n",
            "not christopher\n",
            "not cinderella\n",
            "not cinematic\n",
            "not cinematographer\n",
            "not citizen\n",
            "not claim\n",
            "not claiming\n",
            "not class\n",
            "not clay\n",
            "not clean\n",
            "not cleaning\n",
            "not clichÃ©\n",
            "not clichÃ©s\n",
            "not clothing\n",
            "not club\n",
            "not cohesive\n",
            "not cold\n",
            "not cole\n",
            "not collect\n",
            "not collection\n",
            "not color\n",
            "not colorful\n",
            "not colour\n",
            "not combine\n",
            "not comedian\n",
            "not comic\n",
            "not commenting\n",
            "not communicate\n",
            "not compared\n",
            "not comparison\n",
            "not compelled\n",
            "not compensate\n",
            "not complain\n",
            "not complaint\n",
            "not completed\n",
            "not computer\n",
            "not concentrated\n",
            "not condemned\n",
            "not confirmed\n",
            "not conflict\n",
            "not confused\n",
            "not confusion\n",
            "not connect\n",
            "not connecting\n",
            "not conniving\n",
            "not conscious\n",
            "not conservative\n",
            "not considerably\n",
            "not consideration\n",
            "not considering\n",
            "not contact\n",
            "not contained\n",
            "not continued\n",
            "not continuity\n",
            "not contract\n",
            "not control\n",
            "not controversy\n",
            "not converted\n",
            "not conveyed\n",
            "not convincingly\n",
            "not convoluted\n",
            "not cop\n",
            "not corky\n",
            "not corpses\n",
            "not corrupt\n",
            "not cost\n",
            "not could\n",
            "not country\n",
            "not court\n",
            "not covering\n",
            "not cowboy\n",
            "not crack\n",
            "not cracking\n",
            "not crap\n",
            "not created\n",
            "not creativity\n",
            "not credibility\n",
            "not crime\n",
            "not criminal\n",
            "not cringe\n",
            "not crippled\n",
            "not crisis\n",
            "not crisp\n",
            "not critical\n",
            "not criticize\n",
            "not critics\n",
            "not critique\n",
            "not cross\n",
            "not culkin\n",
            "not cult\n",
            "not current\n",
            "not curse\n",
            "not cutting\n",
            "not cynicism\n",
            "not czech\n",
            "not da\n",
            "not damn\n",
            "not dance\n",
            "not dancer\n",
            "not darn\n",
            "not darren\n",
            "not darth\n",
            "not data\n",
            "not davis\n",
            "not day\n",
            "not de\n",
            "not deadly\n",
            "not december\n",
            "not decided\n",
            "not dedicated\n",
            "not defeat\n",
            "not defeated\n",
            "not defend\n",
            "not define\n",
            "not deliberately\n",
            "not delightful\n",
            "not delivered\n",
            "not demonstrated\n",
            "not denis\n",
            "not depict\n",
            "not depicted\n",
            "not depiction\n",
            "not describe\n",
            "not deserving\n",
            "not desire\n",
            "not desperate\n",
            "not despise\n",
            "not destination\n",
            "not destroyed\n",
            "not detail\n",
            "not determined\n",
            "not developing\n",
            "not device\n",
            "not diary\n",
            "not died\n",
            "not dig\n",
            "not dimensional\n",
            "not dinosaur\n",
            "not disappointing\n",
            "not disaster\n",
            "not disasters\n",
            "not discovering\n",
            "not discussed\n",
            "not disgusted\n",
            "not disgusting\n",
            "not disjointed\n",
            "not dismiss\n",
            "not display\n",
            "not distracted\n",
            "not does\n",
            "not doesn\n",
            "not dog\n",
            "not dollars\n",
            "not dominate\n",
            "not dominated\n",
            "not donald\n",
            "not doomed\n",
            "not doris\n",
            "not double\n",
            "not drab\n",
            "not dracula\n",
            "not dreadful\n",
            "not dreadfully\n",
            "not dreaming\n",
            "not dressing\n",
            "not drinking\n",
            "not drug\n",
            "not drunk\n",
            "not drunken\n",
            "not dry\n",
            "not dukes\n",
            "not dumb\n",
            "not dust\n",
            "not dynamic\n",
            "not dynamite\n",
            "not eager\n",
            "not eagerly\n",
            "not earl\n",
            "not eastwood\n",
            "not eat\n",
            "not edit\n",
            "not editing\n",
            "not elected\n",
            "not elements\n",
            "not embrace\n",
            "not empathize\n",
            "not emphasize\n",
            "not empty\n",
            "not endearing\n",
            "not ended\n",
            "not endless\n",
            "not enduring\n",
            "not engaged\n",
            "not enjoyment\n",
            "not enter\n",
            "not entered\n",
            "not envy\n",
            "not epic\n",
            "not equally\n",
            "not erotic\n",
            "not escape\n",
            "not essentially\n",
            "not establish\n",
            "not european\n",
            "not evidence\n",
            "not evoke\n",
            "not evolution\n",
            "not examine\n",
            "not exceptionally\n",
            "not exciting\n",
            "not executed\n",
            "not exhausted\n",
            "not existence\n",
            "not explaining\n",
            "not explains\n",
            "not explode\n",
            "not exploitation\n",
            "not exploitative\n",
            "not explore\n",
            "not exploring\n",
            "not expose\n",
            "not exposure\n",
            "not express\n",
            "not expressing\n",
            "not fact\n",
            "not factor\n",
            "not factory\n",
            "not failing\n",
            "not fairy\n",
            "not fairytale\n",
            "not fallen\n",
            "not fallon\n",
            "not farnsworth\n",
            "not fascinating\n",
            "not fat\n",
            "not faux\n",
            "not favorite\n",
            "not fbi\n",
            "not feet\n",
            "not femme\n",
            "not fewer\n",
            "not fictional\n",
            "not fighter\n",
            "not figured\n",
            "not filling\n",
            "not filthy\n",
            "not final\n",
            "not finally\n",
            "not finest\n",
            "not firmly\n",
            "not fixed\n",
            "not flashbacks\n",
            "not flashy\n",
            "not flat\n",
            "not flawed\n",
            "not fleshed\n",
            "not flight\n",
            "not florida\n",
            "not focused\n",
            "not folks\n",
            "not following\n",
            "not food\n",
            "not fooled\n",
            "not footage\n",
            "not foremost\n",
            "not forgive\n",
            "not form\n",
            "not fortune\n",
            "not four\n",
            "not freaky\n",
            "not frenetic\n",
            "not friendly\n",
            "not friends\n",
            "not friendship\n",
            "not frightened\n",
            "not fritz\n",
            "not fulci\n",
            "not function\n",
            "not funnier\n",
            "not further\n",
            "not fuzzy\n",
            "not gackt\n",
            "not gag\n",
            "not game\n",
            "not gandhi\n",
            "not garden\n",
            "not garner\n",
            "not gas\n",
            "not gem\n",
            "not gen\n",
            "not general\n",
            "not generate\n",
            "not generated\n",
            "not genie\n",
            "not geoffrey\n",
            "not georges\n",
            "not german\n",
            "not germans\n",
            "not gets\n",
            "not ghosts\n",
            "not giallo\n",
            "not girl\n",
            "not girls\n",
            "not glad\n",
            "not glamorous\n",
            "not glaring\n",
            "not glass\n",
            "not glossy\n",
            "not gods\n",
            "not golden\n",
            "not gore\n",
            "not gorgeous\n",
            "not grant\n",
            "not granted\n",
            "not grasp\n",
            "not greater\n",
            "not greatly\n",
            "not grossly\n",
            "not groundbreaking\n",
            "not grounds\n",
            "not group\n",
            "not growing\n",
            "not grown\n",
            "not gruesome\n",
            "not guessing\n",
            "not guilt\n",
            "not gus\n",
            "not gut\n",
            "not guys\n",
            "not gwyneth\n",
            "not gypsy\n",
            "not hallmark\n",
            "not ham\n",
            "not hand\n",
            "not handed\n",
            "not handle\n",
            "not happened\n",
            "not happiness\n",
            "not hardcore\n",
            "not harry\n",
            "not harsh\n",
            "not hateful\n",
            "not hating\n",
            "not haven\n",
            "not hayden\n",
            "not healthy\n",
            "not heartless\n",
            "not helicopter\n",
            "not hell\n",
            "not henry\n",
            "not heroes\n",
            "not heroic\n",
            "not hiring\n",
            "not history\n",
            "not hitler\n",
            "not hmm\n",
            "not hook\n",
            "not hope\n",
            "not hoped\n",
            "not hopelessly\n",
            "not horny\n",
            "not horrendous\n",
            "not hostel\n",
            "not hour\n",
            "not house\n",
            "not hugely\n",
            "not humorous\n",
            "not hundreds\n",
            "not hungry\n",
            "not hurts\n",
            "not huston\n",
            "not hybrid\n",
            "not hype\n",
            "not idea\n",
            "not identify\n",
            "not ignore\n",
            "not ignored\n",
            "not ill\n",
            "not illiterate\n",
            "not imitate\n",
            "not improbable\n",
            "not incomprehensible\n",
            "not incredibly\n",
            "not indeed\n",
            "not india\n",
            "not indian\n",
            "not indicate\n",
            "not indifference\n",
            "not inform\n",
            "not ingenious\n",
            "not initially\n",
            "not injured\n",
            "not innocent\n",
            "not insightful\n",
            "not insignificant\n",
            "not insist\n",
            "not inspector\n",
            "not inspire\n",
            "not inspired\n",
            "not intention\n",
            "not intentional\n",
            "not inter\n",
            "not interact\n",
            "not interviewed\n",
            "not inventive\n",
            "not invited\n",
            "not iran\n",
            "not iranian\n",
            "not iraq\n",
            "not irene\n",
            "not ironically\n",
            "not irrelevant\n",
            "not irritated\n",
            "not isabelle\n",
            "not islam\n",
            "not issue\n",
            "not jack\n",
            "not jar\n",
            "not jason\n",
            "not jean\n",
            "not jessica\n",
            "not jews\n",
            "not joe\n",
            "not johnny\n",
            "not jordan\n",
            "not judd\n",
            "not judging\n",
            "not jumping\n",
            "not junk\n",
            "not justification\n",
            "not justified\n",
            "not juvenile\n",
            "not kane\n",
            "not kate\n",
            "not kathy\n",
            "not kay\n",
            "not keitel\n",
            "not kelly\n",
            "not kept\n",
            "not kicking\n",
            "not killers\n",
            "not kinda\n",
            "not kirsten\n",
            "not knightley\n",
            "not knows\n",
            "not kolchak\n",
            "not kung\n",
            "not la\n",
            "not ladder\n",
            "not ladies\n",
            "not lame\n",
            "not landed\n",
            "not laputa\n",
            "not large\n",
            "not lasted\n",
            "not late\n",
            "not launched\n",
            "not leading\n",
            "not leads\n",
            "not learn\n",
            "not legitimate\n",
            "not leonard\n",
            "not lesbian\n",
            "not leslie\n",
            "not liberal\n",
            "not lighting\n",
            "not limit\n",
            "not lindsey\n",
            "not line\n",
            "not linear\n",
            "not lines\n",
            "not link\n",
            "not linked\n",
            "not lip\n",
            "not listened\n",
            "not lived\n",
            "not load\n",
            "not loaded\n",
            "not london\n",
            "not loose\n",
            "not lord\n",
            "not loved\n",
            "not lover\n",
            "not lovers\n",
            "not loving\n",
            "not lower\n",
            "not luckily\n",
            "not machine\n",
            "not magazine\n",
            "not maggie\n",
            "not magician\n",
            "not maintain\n",
            "not makes\n",
            "not manipulate\n",
            "not manipulation\n",
            "not margaret\n",
            "not mark\n",
            "not marked\n",
            "not marshall\n",
            "not martial\n",
            "not marvel\n",
            "not mary\n",
            "not masterfully\n",
            "not matching\n",
            "not mature\n",
            "not maureen\n",
            "not may\n",
            "not mayor\n",
            "not means\n",
            "not meanwhile\n",
            "not measure\n",
            "not medical\n",
            "not medium\n",
            "not mel\n",
            "not melodramatic\n",
            "not member\n",
            "not members\n",
            "not men\n",
            "not mental\n",
            "not meryl\n",
            "not mess\n",
            "not message\n",
            "not messing\n",
            "not method\n",
            "not michelle\n",
            "not mild\n",
            "not military\n",
            "not milk\n",
            "not million\n",
            "not minutes\n",
            "not mira\n",
            "not miserably\n",
            "not misleading\n",
            "not mixed\n",
            "not mixing\n",
            "not mon\n",
            "not money\n",
            "not monkeys\n",
            "not montana\n",
            "not monumental\n",
            "not mood\n",
            "not moody\n",
            "not moral\n",
            "not morally\n",
            "not morgan\n",
            "not morons\n",
            "not mortal\n",
            "not mostly\n",
            "not motivated\n",
            "not movies\n",
            "not mrs\n",
            "not mtv\n",
            "not muddled\n",
            "not multi\n",
            "not murder\n",
            "not myrtle\n",
            "not mysterious\n",
            "not nail\n",
            "not naive\n",
            "not nancy\n",
            "not narrative\n",
            "not nasty\n",
            "not natalie\n",
            "not nation\n",
            "not native\n",
            "not natural\n",
            "not nazi\n",
            "not neat\n",
            "not necessity\n",
            "not needing\n",
            "not neil\n",
            "not newcomer\n",
            "not nicolas\n",
            "not non\n",
            "not norwegian\n",
            "not notable\n",
            "not note\n",
            "not noted\n",
            "not noticed\n",
            "not notorious\n",
            "not novel\n",
            "not nudity\n",
            "not object\n",
            "not objective\n",
            "not obscure\n",
            "not obsessed\n",
            "not obviously\n",
            "not offered\n",
            "not offers\n",
            "not okay\n",
            "not ones\n",
            "not opened\n",
            "not option\n",
            "not order\n",
            "not origin\n",
            "not ostensibly\n",
            "not otherwise\n",
            "not outdated\n",
            "not outside\n",
            "not overblown\n",
            "not overlooked\n",
            "not overrated\n",
            "not overshadowed\n",
            "not overt\n",
            "not overweight\n",
            "not overwhelming\n",
            "not owns\n",
            "not paced\n",
            "not pack\n",
            "not paid\n",
            "not painfully\n",
            "not painted\n",
            "not paired\n",
            "not pan\n",
            "not paper\n",
            "not parallel\n",
            "not parent\n",
            "not parents\n",
            "not partial\n",
            "not partially\n",
            "not particular\n",
            "not partner\n",
            "not parts\n",
            "not party\n",
            "not passed\n",
            "not passive\n",
            "not patrick\n",
            "not pavarotti\n",
            "not pays\n",
            "not peculiar\n",
            "not penny\n",
            "not perfection\n",
            "not performances\n",
            "not performed\n",
            "not personal\n",
            "not pets\n",
            "not petty\n",
            "not pg\n",
            "not phone\n",
            "not phony\n",
            "not photographed\n",
            "not physics\n",
            "not pia\n",
            "not picked\n",
            "not piece\n",
            "not pity\n",
            "not pivotal\n",
            "not placed\n",
            "not places\n",
            "not plain\n",
            "not planet\n",
            "not planned\n",
            "not planning\n",
            "not plans\n",
            "not plant\n",
            "not playful\n",
            "not plays\n",
            "not plug\n",
            "not plus\n",
            "not points\n",
            "not pokemon\n",
            "not pompous\n",
            "not pop\n",
            "not portraying\n",
            "not pose\n",
            "not position\n",
            "not positive\n",
            "not power\n",
            "not preaching\n",
            "not predict\n",
            "not prefer\n",
            "not preparing\n",
            "not prequel\n",
            "not presentation\n",
            "not presenting\n",
            "not presumably\n",
            "not previous\n",
            "not previously\n",
            "not primarily\n",
            "not prisoner\n",
            "not prize\n",
            "not problems\n",
            "not produced\n",
            "not product\n",
            "not profanity\n",
            "not prominent\n",
            "not promise\n",
            "not promotion\n",
            "not prone\n",
            "not prophet\n",
            "not proud\n",
            "not provided\n",
            "not proving\n",
            "not pseudo\n",
            "not psychiatric\n",
            "not psychological\n",
            "not psychologist\n",
            "not purpose\n",
            "not python\n",
            "not quick\n",
            "not quirky\n",
            "not racial\n",
            "not radio\n",
            "not rain\n",
            "not randy\n",
            "not rating\n",
            "not reaches\n",
            "not realized\n",
            "not reasonably\n",
            "not recall\n",
            "not receiving\n",
            "not recognizable\n",
            "not recreate\n",
            "not reel\n",
            "not reference\n",
            "not references\n",
            "not reflected\n",
            "not reflection\n",
            "not refuse\n",
            "not regard\n",
            "not reject\n",
            "not relatively\n",
            "not release\n",
            "not releasing\n",
            "not relying\n",
            "not remarkable\n",
            "not remembering\n",
            "not remove\n",
            "not rendered\n",
            "not report\n",
            "not representing\n",
            "not repulsive\n",
            "not resolve\n",
            "not resolved\n",
            "not resort\n",
            "not respect\n",
            "not respectable\n",
            "not respected\n",
            "not respond\n",
            "not restrained\n",
            "not retelling\n",
            "not retired\n",
            "not reunion\n",
            "not revenge\n",
            "not reviewing\n",
            "not reward\n",
            "not reynolds\n",
            "not ride\n",
            "not ridiculously\n",
            "not rob\n",
            "not robin\n",
            "not rock\n",
            "not rocket\n",
            "not rodney\n",
            "not roll\n",
            "not room\n",
            "not rooting\n",
            "not route\n",
            "not royal\n",
            "not rub\n",
            "not ruined\n",
            "not runs\n",
            "not russia\n",
            "not russian\n",
            "not said\n",
            "not saint\n",
            "not salvage\n",
            "not salvation\n",
            "not same\n",
            "not san\n",
            "not sandler\n",
            "not sandra\n",
            "not sasquatch\n",
            "not satirical\n",
            "not satisfactory\n",
            "not savage\n",
            "not saved\n",
            "not scale\n",
            "not scarier\n",
            "not scarlett\n",
            "not schlock\n",
            "not schneider\n",
            "not scifi\n",
            "not scratch\n",
            "not scratching\n",
            "not seagal\n",
            "not sealed\n",
            "not sean\n",
            "not searching\n",
            "not secondary\n",
            "not seconds\n",
            "not seductive\n",
            "not seedy\n",
            "not seeking\n",
            "not seems\n",
            "not sensible\n",
            "not sent\n",
            "not sentences\n",
            "not sequence\n",
            "not sequences\n",
            "not serbian\n",
            "not series\n",
            "not seriously\n",
            "not served\n",
            "not settle\n",
            "not several\n",
            "not sexual\n",
            "not sexuality\n",
            "not shame\n",
            "not sharing\n",
            "not shed\n",
            "not sheep\n",
            "not shining\n",
            "not shock\n",
            "not shocked\n",
            "not shout\n",
            "not shred\n",
            "not sibling\n",
            "not side\n",
            "not sign\n",
            "not signs\n",
            "not sinatra\n",
            "not sincere\n",
            "not singer\n",
            "not sinister\n",
            "not sink\n",
            "not site\n",
            "not situation\n",
            "not skill\n",
            "not skinny\n",
            "not skipping\n",
            "not slam\n",
            "not slap\n",
            "not sleeping\n",
            "not slim\n",
            "not smaller\n",
            "not smiling\n",
            "not soap\n",
            "not sober\n",
            "not social\n",
            "not sold\n",
            "not soldier\n",
            "not sole\n",
            "not somebody\n",
            "not somehow\n",
            "not sometimes\n",
            "not somewhat\n",
            "not son\n",
            "not song\n",
            "not songs\n",
            "not sophisticated\n",
            "not spanish\n",
            "not specifically\n",
            "not spectacularly\n",
            "not spielberg\n",
            "not split\n",
            "not spoof\n",
            "not spooky\n",
            "not square\n",
            "not st\n",
            "not stabbing\n",
            "not stack\n",
            "not stage\n",
            "not staged\n",
            "not staging\n",
            "not standard\n",
            "not starring\n",
            "not stating\n",
            "not stayed\n",
            "not staying\n",
            "not steel\n",
            "not steele\n",
            "not step\n",
            "not stepmother\n",
            "not stereotypical\n",
            "not steve\n",
            "not steven\n",
            "not stevens\n",
            "not stick\n",
            "not stinker\n",
            "not stones\n",
            "not stood\n",
            "not straightforward\n",
            "not strange\n",
            "not stress\n",
            "not striking\n",
            "not studio\n",
            "not studying\n",
            "not stunningly\n",
            "not stylish\n",
            "not success\n",
            "not sucker\n",
            "not sucks\n",
            "not suffering\n",
            "not suggest\n",
            "not suggested\n",
            "not sunny\n",
            "not superbly\n",
            "not superficial\n",
            "not supernatural\n",
            "not supply\n",
            "not surface\n",
            "not surrender\n",
            "not surrogate\n",
            "not survived\n",
            "not suspect\n",
            "not suspend\n",
            "not swedish\n",
            "not swim\n",
            "not switch\n",
            "not symbolism\n",
            "not tacked\n",
            "not tackle\n",
            "not tacky\n",
            "not tale\n",
            "not talent\n",
            "not tame\n",
            "not tap\n",
            "not tarantino\n",
            "not target\n",
            "not targets\n",
            "not tax\n",
            "not tea\n",
            "not teach\n",
            "not teaching\n",
            "not team\n",
            "not television\n",
            "not tempted\n",
            "not tender\n",
            "not tense\n",
            "not term\n",
            "not terrific\n",
            "not terrorists\n",
            "not texas\n",
            "not thank\n",
            "not theatrical\n",
            "not theme\n",
            "not theo\n",
            "not thereby\n",
            "not third\n",
            "not thoughtful\n",
            "not threatening\n",
            "not thrust\n",
            "not tie\n",
            "not tied\n",
            "not times\n",
            "not titled\n",
            "not todays\n",
            "not todd\n",
            "not toe\n",
            "not toilet\n",
            "not tommy\n",
            "not ton\n",
            "not tongue\n",
            "not tony\n",
            "not tour\n",
            "not towards\n",
            "not toxic\n",
            "not toy\n",
            "not tradition\n",
            "not traditional\n",
            "not trailer\n",
            "not train\n",
            "not transformed\n",
            "not transformers\n",
            "not translation\n",
            "not transported\n",
            "not trapped\n",
            "not travesty\n",
            "not trend\n",
            "not triangle\n",
            "not tribute\n",
            "not tricked\n",
            "not trio\n",
            "not trip\n",
            "not trite\n",
            "not trusted\n",
            "not truth\n",
            "not truthful\n",
            "not tsui\n",
            "not turkish\n",
            "not tv\n",
            "not twins\n",
            "not twist\n",
            "not un\n",
            "not unattractive\n",
            "not unbearable\n",
            "not uncle\n",
            "not unfortunately\n",
            "not unfunny\n",
            "not unhappy\n",
            "not united\n",
            "not universal\n",
            "not unsympathetic\n",
            "not untrue\n",
            "not unwatchable\n",
            "not upset\n",
            "not us\n",
            "not utter\n",
            "not vague\n",
            "not valid\n",
            "not varied\n",
            "not various\n",
            "not venture\n",
            "not versatile\n",
            "not vertigo\n",
            "not vet\n",
            "not vhs\n",
            "not vice\n",
            "not victim\n",
            "not victims\n",
            "not victor\n",
            "not victoria\n",
            "not video\n",
            "not vietnam\n",
            "not viewed\n",
            "not viewing\n",
            "not vile\n",
            "not villain\n",
            "not vivian\n",
            "not void\n",
            "not voting\n",
            "not wagner\n",
            "not waiting\n",
            "not wake\n",
            "not wal\n",
            "not walking\n",
            "not wall\n",
            "not wander\n",
            "not wannabe\n",
            "not warm\n",
            "not warn\n",
            "not warned\n",
            "not warrant\n",
            "not warrior\n",
            "not warriors\n",
            "not washed\n",
            "not wasn\n",
            "not wastes\n",
            "not watchable\n",
            "not wayne\n",
            "not weakness\n",
            "not wealthy\n",
            "not weapon\n",
            "not web\n",
            "not week\n",
            "not weird\n",
            "not welcomed\n",
            "not were\n",
            "not whatever\n",
            "not whether\n",
            "not whilst\n",
            "not whiny\n",
            "not wide\n",
            "not widow\n",
            "not wildly\n",
            "not wing\n",
            "not wishing\n",
            "not wit\n",
            "not within\n",
            "not witless\n",
            "not witnessed\n",
            "not wonder\n",
            "not wonderful\n",
            "not wondering\n",
            "not wont\n",
            "not woo\n",
            "not wood\n",
            "not woody\n",
            "not words\n",
            "not worn\n",
            "not worthless\n",
            "not wow\n",
            "not wrap\n",
            "not wreck\n",
            "not writer\n",
            "not writing\n",
            "not ww2\n",
            "not year\n",
            "not yell\n",
            "not yes\n",
            "not yesterday\n",
            "not yourself\n",
            "not zombie\n",
            "not zone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words12 = np.array([len(bigrams),2])\n",
        "#create a 2D matrix\n",
        "for f in bigrams\n",
        "  words12 = \n",
        "#import re\n",
        "#re.findall(\"^not\", bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVnWiy9sVvhW",
        "outputId": "de4cbd2e-21de-437b-8ec2-9a92fca10480"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_sk_bi.get_feature_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ8N4SoAEM9G",
        "outputId": "7df00d67-2499-4d85-e799-bcba70529f16"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<25000x177 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 492382 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCGteqesJJf9"
      },
      "source": [
        "\n",
        "## NLP in spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')"
      ],
      "metadata": {
        "id": "xgo8-H37hrmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u\"Apples and oranges are similar. Boots and hippos aren't.\")\n",
        "\n",
        "\n",
        "for token in doc:\n",
        "    print(token,  token.lemma_)\n",
        "    #printt(token.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT0C-uI0h50V",
        "outputId": "591975e0-a87b-4337-92e5-57c4a5da2e17"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apples apple\n",
            "and and\n",
            "oranges orange\n",
            "are be\n",
            "similar similar\n",
            ". .\n",
            "Boots boot\n",
            "and and\n",
            "hippos hippos\n",
            "are be\n",
            "n't not\n",
            ". .\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Class2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}